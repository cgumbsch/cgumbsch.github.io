---
title: Developing Hierarchical Anticipations from Sparse Latent State Changes
layout: post
post-image: "https://raw.githubusercontent.com/cgumbsch/cgumbsch.github.io/master/assets/images/skips.gif"
post-info: <span style="color:grey"> <b> Christian Gumbsch </b>, Maurits Adam, Birgit Elsner, Georg Martius & Martin V. Butz  </span> <br>  <span style="color:grey"> <i> IEEE ICDL</i>, 2022 </span>   <span style="color:red">(</span> <a href="https://x.com/IEEE_ICDL/status/1571903478636609536" target="_blank" class="has-text-red">SmartBot award winner</i></a> <span style="color:red">, oral)</span> <br> <a href="https://arxiv.org/pdf/2206.02042.pdf" target="_blank" class="has-text-blue">Paper</i></a>, <a href="https://github.com/CognitiveModeling/HierarchicalGateL0RD" target="_blank" class="has-text-blue">Code</i></a>, <a href="https://twitter.com/cgumbsch/status/1568131447545860097?s=20&t=D_h69wL1zwMH4VdfiRswDg" target="_blank" class="has-text-blue">Twitter</i></a>  
description: TL;DR We propose a recurrent neural network with two levels that learns, in a fully self-supervised way, to make hierarchical, temporal abstract predictions about its future inputs.
tags:
- hierarchical prediction
- goal-anticipation
- predictive gaze
- event segmentation
- developmental robotics
---

Humans can make predictions on various time scales. Can we give this ability to a recurrent neural network (RNN)? In our paper, we present a hierarchical RNN that develops temporal abstract predictions on the higher level - by chopping up time series into segments with constant latent activity...

### Abstract

Humans can make predictions on various time scales and hierarchical levels. Thereby, the learning of event encodings seems to play a crucial role. In this work we model the development of hierarchical predictions via autonomously learned latent event codes. We present a hierarchical recurrent neural network architecture, whose inductive learning biases foster the development of sparsely changing latent state that compress sensorimotor sequences. A higher level network learns to predict the situations in which the latent states tend to change. Using a simulated robotic manipulator, we demonstrate that the system (i) learns latent states that accurately reflect the event structure of the data, (ii) develops meaningful temporal abstract predictions on the higher level, and (iii) generates goal-anticipatory behavior similar to gaze behavior found in eye-tracking studies with infants. The architecture offers a step towards the autonomous learning of compressed hierarchical encodings of gathered experiences and the exploitation of these encodings to generate adaptive behavior. 

### More information
- :page_facing_up: [ArXiv paper](https://arxiv.org/pdf/2206.02042.pdf){:target="_blank"}
- :bird: [Twitter thread](https://twitter.com/cgumbsch/status/1568131447545860097?s=20&t=D_h69wL1zwMH4VdfiRswDg){:target="_blank"}
- :snake: [Code](https://github.com/CognitiveModeling/HierarchicalGateL0RD){:target="_blank"}
